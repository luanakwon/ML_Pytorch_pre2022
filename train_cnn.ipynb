{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1GIxDwqXkAnrZnoijdQ7BNmiNod8O3HLc",
      "authorship_tag": "ABX9TyN2qQOhErfH2VLrFoVb5fAL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luanakwon/ML_Pytorch_pre2022/blob/main/train_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Omok  \n",
        "---\n",
        "Simple omok AI using CNN. (probably a little modification of some tuto) "
      ],
      "metadata": {
        "id": "W0v90bJjB56B"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVYMlA5HAuo3"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "import os\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1A1qrIRQucS",
        "outputId": "c97c68ef-6296-4118-f1b6-1436efcf143b"
      },
      "source": [
        "h, w = 20,20\n",
        "\n",
        "base_path = 'drive/MyDrive/omok/dataset/*.npz'\n",
        "\n",
        "file_list = glob(base_path)\n",
        "\n",
        "x_data, y_data = [],[]\n",
        "for index, file_path in enumerate(file_list):\n",
        "  if index < 3000:\n",
        "    continue\n",
        "  elif index < 3500:\n",
        "    print(\"\\r%d\" % index, end='')\n",
        "  else:\n",
        "    break\n",
        "  data = np.load(file_path)\n",
        "  x_data.extend(data['inputs'])\n",
        "  y_data.extend(data['outputs'])\n",
        "  \n",
        "\n",
        "x_val = np.array(x_data, np.float32).reshape((-1,h,w,1))\n",
        "y_val = np.array(y_data, np.float32).reshape((-1,h*w))\n",
        "\n",
        "#x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=2020)\n",
        "\n",
        "del x_data, y_data\n",
        "\n",
        "#print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3499(277356, 20, 20, 1) (277356, 400)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mq6LTEIFTl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb5d25c-7a94-4183-eb85-fb47e26fbe08"
      },
      "source": [
        "model = models.Sequential([\n",
        "  layers.Conv2D(64,7,activation='relu', padding='same', input_shape=(h,w,1)),\n",
        "  layers.Conv2D(128,7,activation='relu',padding='same'),\n",
        "  layers.Conv2D(256,7,activation='relu',padding='same'), \n",
        "  layers.Conv2D(128,7,activation='relu',padding='same'),\n",
        "  layers.Conv2D(64,7,activation='relu',padding='same'),   \n",
        "  layers.Conv2D(1,1,activation=None,padding='same'), \n",
        "  layers.Reshape((h*w,)),\n",
        "  layers.Activation('sigmoid') \n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 20, 20, 64)        3200      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 20, 20, 128)       401536    \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 20, 20, 256)       1605888   \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 20, 20, 128)       1605760   \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 20, 20, 64)        401472    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 20, 20, 1)         65        \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 400)               0         \n",
            "=================================================================\n",
            "Total params: 4,017,921\n",
            "Trainable params: 4,017,921\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qK--fb-dQ4W",
        "outputId": "3a1e508f-65d9-43e7-f162-22b7f30f28e8"
      },
      "source": [
        "checkpoint_path = 'drive/MyDrive/omok/checkpoints/best.h5'\n",
        "\n",
        "#model.load_weights(checkpoint_path)\n",
        "\n",
        "model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=256,\n",
        "    epochs=10,\n",
        "    callbacks=[ModelCheckpoint(checkpoint_path,monitor='val_acc',save_best_only=True,verbose=1,mode='auto'),\n",
        "      ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, mode='auto')\n",
        "    ],\n",
        "    validation_data=(x_val, y_val),\n",
        "    use_multiprocessing=True,\n",
        "    workers=16\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4567/4567 [==============================] - 598s 129ms/step - loss: 0.0162 - acc: 0.2051 - val_loss: 0.0072 - val_acc: 0.4746\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.47458, saving model to drive/MyDrive/omok/checkpoints/best.h5\n",
            "Epoch 2/10\n",
            "4567/4567 [==============================] - 606s 133ms/step - loss: 0.0070 - acc: 0.4857 - val_loss: 0.0065 - val_acc: 0.5052\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.47458 to 0.50516, saving model to drive/MyDrive/omok/checkpoints/best.h5\n",
            "Epoch 3/10\n",
            "4567/4567 [==============================] - 607s 133ms/step - loss: 0.0063 - acc: 0.5168 - val_loss: 0.0061 - val_acc: 0.5212\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.50516 to 0.52121, saving model to drive/MyDrive/omok/checkpoints/best.h5\n",
            "Epoch 4/10\n",
            "4567/4567 [==============================] - 612s 134ms/step - loss: 0.0058 - acc: 0.5477 - val_loss: 0.0060 - val_acc: 0.5344\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.52121 to 0.53442, saving model to drive/MyDrive/omok/checkpoints/best.h5\n",
            "Epoch 5/10\n",
            "4567/4567 [==============================] - 618s 135ms/step - loss: 0.0054 - acc: 0.5811 - val_loss: 0.0058 - val_acc: 0.5532\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.53442 to 0.55317, saving model to drive/MyDrive/omok/checkpoints/best.h5\n",
            "Epoch 6/10\n",
            "4567/4567 [==============================] - 620s 136ms/step - loss: 0.0050 - acc: 0.6184 - val_loss: 0.0057 - val_acc: 0.5646\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.55317 to 0.56464, saving model to drive/MyDrive/omok/checkpoints/best.h5\n",
            "Epoch 7/10\n",
            "4567/4567 [==============================] - 623s 136ms/step - loss: 0.0045 - acc: 0.6574 - val_loss: 0.0057 - val_acc: 0.5791\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.56464 to 0.57909, saving model to drive/MyDrive/omok/checkpoints/best.h5\n",
            "Epoch 8/10\n",
            "4567/4567 [==============================] - 626s 137ms/step - loss: 0.0042 - acc: 0.6925 - val_loss: 0.0057 - val_acc: 0.5942\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.57909 to 0.59415, saving model to drive/MyDrive/omok/checkpoints/best.h5\n",
            "Epoch 9/10\n",
            "4567/4567 [==============================] - 626s 137ms/step - loss: 0.0038 - acc: 0.7235 - val_loss: 0.0056 - val_acc: 0.6070\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.59415 to 0.60700, saving model to drive/MyDrive/omok/checkpoints/best.h5\n",
            "Epoch 10/10\n",
            "4567/4567 [==============================] - 626s 137ms/step - loss: 0.0036 - acc: 0.7492 - val_loss: 0.0057 - val_acc: 0.6202\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.60700 to 0.62023, saving model to drive/MyDrive/omok/checkpoints/best.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f87201566d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "ziKrVzjxBjvQ",
        "outputId": "19e075e3-0049-44e9-c6fd-691c9d814a70"
      },
      "source": [
        "\n",
        "checkpoint_path = 'drive/MyDrive/omok/checkpoints/best.h5'\n",
        "model.load_weights(checkpoint_path)\n",
        "model.evaluate(x_val,y_val,batch_size=50,workers=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  36/5548 [..............................] - ETA: 3:55:02 - loss: 0.0042 - acc: 0.6842"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c96c3cdc9a7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'drive/MyDrive/omok/checkpoints/best.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09dbHDjLPA-D",
        "outputId": "7060ccaf-f2b4-462e-bfbc-3fec0d132ba9"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "class Game:\n",
        "  def __init__(self, model):\n",
        "    self.board = np.zeros((20,20),dtype=np.int8)\n",
        "    self.model = model\n",
        "\n",
        "  def usrTurn(self):\n",
        "    while True:\n",
        "      print(\"your turn : x y\")\n",
        "      x, y = map(int, input().split())\n",
        "      if self.board[y,x] == 0:\n",
        "        self.board[y,x] = -1\n",
        "        clear_output()\n",
        "        self.printBoard()\n",
        "        print(\"usr placed black at %d,%d\"%(x,y))\n",
        "        break\n",
        "      else:\n",
        "        clear_output()\n",
        "        print(\"wrong position\")\n",
        "\n",
        "  def aiTurn(self):\n",
        "    input = np.expand_dims(self.board, axis = (0,-1)).astype(np.float32)\n",
        "\n",
        "    output = self.model.predict(input).squeeze()\n",
        "    output = output.reshape((h,w))\n",
        "    oy, ox = np.unravel_index(np.argmax(output), output.shape)\n",
        "    if self.board[oy,ox] == 0:\n",
        "      self.board[oy,ox] = 1\n",
        "      clear_output()\n",
        "      self.printBoard()\n",
        "      print(\"AI placed white at %d,%d\"%(ox,oy))\n",
        "    else:\n",
        "      clear_output()\n",
        "      print(\"AI error\")\n",
        "\n",
        "  def game_over(self):\n",
        "    \n",
        "    for p in [-1,1]:\n",
        "      for i, row in enumerate(self.board):\n",
        "        for j, e in enumerate(row):\n",
        "          if e == p:\n",
        "            if j < 16 and np.all(self.board[i,j:j+5] == p):\n",
        "              return p\n",
        "            if i < 16 and np.all(self.board[i:i+5,j] == p):\n",
        "              return p\n",
        "            if i<16 and j<16 and np.all(np.diagonal(self.board[i:i+5,j:j+5])==p):\n",
        "              return p\n",
        "    return 0\n",
        "\n",
        "  def gamestart(self):\n",
        "    while True:\n",
        "      self.usrTurn()\n",
        "      p = self.game_over()\n",
        "      if p != 0:\n",
        "        print(\"player {} wins\".format(p))\n",
        "        break\n",
        "      self.aiTurn()\n",
        "      p = self.game_over()\n",
        "      if p != 0:\n",
        "        print(\"player %d wins\"%(p))\n",
        "        break\n",
        "\n",
        "  def printBoard(self):\n",
        "    num = '   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9'\n",
        "    print(num)\n",
        "    for i, row in enumerate(self.board):\n",
        "      print(\"%2d \"%i, end='')\n",
        "      for el in row:\n",
        "        if el == 0:\n",
        "          print('.', end=' ')\n",
        "        elif el == 1:\n",
        "          print('0', end=' ')\n",
        "        else:\n",
        "          print('@', end=' ')\n",
        "      print()\n",
        "    \n",
        "\n",
        "game = Game(model)\n",
        "game.gamestart()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9\n",
            " 0 . . . . . . . . . . . . . . . . . . . . \n",
            " 1 . . . . . . . . . . . . . . . . . . . . \n",
            " 2 . . . . . . . . . . . . . . . . . . . . \n",
            " 3 . . . . . . . . . . . . . . . . . . . . \n",
            " 4 . . . . . . . . . . . . . . . . . . . . \n",
            " 5 . . . . . . . . . . . . . . . . . . . . \n",
            " 6 . . . . . . . . . . . . . . . . . . . . \n",
            " 7 . . . . . . . 0 . . . . . . . . . . . . \n",
            " 8 . . . . . . . . @ . . 0 . . . . . . . . \n",
            " 9 . . . . . . . @ . @ 0 @ . . . . . . . . \n",
            "10 . . . . @ 0 0 0 0 0 @ @ . . . . . . . . \n",
            "11 . . . . . . . . @ 0 . @ . . . . . . . . \n",
            "12 . . . . . . . . . @ . . 0 . . . . . . . \n",
            "13 . . . . . . . . . . . . . . . . . . . . \n",
            "14 . . . . . . . . . . . . . . . . . . . . \n",
            "15 . . . . . . . . . . . . . . . . . . . . \n",
            "16 . . . . . . . . . . . . . . . . . . . . \n",
            "17 . . . . . . . . . . . . . . . . . . . . \n",
            "18 . . . . . . . . . . . . . . . . . . . . \n",
            "19 . . . . . . . . . . . . . . . . . . . . \n",
            "AI placed white at 5,10\n",
            "player 1 wins\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}